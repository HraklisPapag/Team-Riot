{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a combination of all the things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "#from tweepy.streaming import StreamListener\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import string\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from cmath import nan\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Word processing libraries\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from shapely.geometry import LineString\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point, Polygon\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Query From Vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = pd.read_excel('DATA/Protest-Query.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_or(l):\n",
    "    out = ''\n",
    "    for index, word in enumerate(l):\n",
    "        if word == word:\n",
    "            out += word + ' OR '\n",
    "\n",
    "    out = out[:(len(out)-4)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_kw= list(query_df['University Key Words'])\n",
    "uni_kw_string = list_to_or(uni_kw)\n",
    "\n",
    "unis= list(query_df['List of Universities'])\n",
    "unis_string = list_to_or(unis)\n",
    "\n",
    "actions= list(query_df['Actions'])\n",
    "actions_string = list_to_or(actions)\n",
    "\n",
    "other= list(query_df['Other'])\n",
    "other_string = list_to_or(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ('((' + uni_kw_string + ' OR '\n",
    "            + unis_string + ') ('\n",
    "            + actions_string + ' OR '\n",
    "            + other_string + '))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query += ' -is:retweet lang:en place_country:ZA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Tweet Data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticating Twitter API\n",
    "# Obtain your Twitter credentials from your twitter developer account\n",
    "\n",
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAEGchQEAAAAAZSYFv1nyLDV81YAKEfDr1fVrlho%3DWKBvyLhQ4CeHrlBRtecAetYkB1ZnAjI3Zydb1516fkIzKhS4vh'\n",
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = query\n",
    "date_since = datetime.datetime(2015,10,1)\n",
    "date_before = datetime.datetime(2017,12,31)\n",
    "numTweets = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Tweets\n",
    "# Note for the final versions we should use -> until_id -> allos to resume scraping from a particualar tweet ID\n",
    "protest_tweets = []\n",
    "count = 0 \n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = search_words,\n",
    "                                 user_fields = ['public_metrics'],\n",
    "                                 tweet_fields = ['created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 place_fields = ['id', 'geo', 'name', 'country_code', 'place_type', 'full_name', 'country'],\n",
    "                                 expansions = ['author_id', 'geo.place_id'],\n",
    "                                 start_time = date_since,\n",
    "                                 end_time = date_before,\n",
    "                                 max_results=numTweets\n",
    "                              ):\n",
    "   time.sleep(1)\n",
    "   protest_tweets.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populating Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981  result(s) were excluded due to invalid data points.\n"
     ]
    }
   ],
   "source": [
    "error_count = 0\n",
    "result = []\n",
    "user_dict = {}\n",
    "place_dict = {}\n",
    "# Loop through each response object\n",
    "for response in protest_tweets:\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        user_dict[user.id] = {'followers': user.public_metrics['followers_count'],\n",
    "                              'tweets': user.public_metrics['tweet_count'],\n",
    "                             }\n",
    "    \n",
    "    place_dict = {p['id']: p for p in response.includes['places']}\n",
    "\n",
    "    for tweet in response.data:\n",
    "        # For each tweet, find the author's information\n",
    "        author_info = user_dict[tweet.author_id]\n",
    "        # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "\n",
    "        try:\n",
    "            if place_dict[tweet.geo['place_id']]:\n",
    "                place = place_dict[tweet.geo['place_id']]   \n",
    "            else:\n",
    "                place = nan\n",
    "\n",
    "            result.append({'tweet_id': tweet.id,\n",
    "                       'author_followers': author_info['followers'],\n",
    "                       'text': tweet.text,\n",
    "                       'created_at': tweet.created_at,\n",
    "                       'retweets': tweet.public_metrics['retweet_count'],\n",
    "                       'replies': tweet.public_metrics['reply_count'],\n",
    "                       'likes': tweet.public_metrics['like_count'],\n",
    "                       'quote_count': tweet.public_metrics['quote_count'],\n",
    "                       'place_id': tweet.geo,\n",
    "                       'place_name': place.full_name,\n",
    "                       'bbox': place.geo['bbox']\n",
    "\n",
    "                      })\n",
    "\n",
    "        except:\n",
    "            error_count = error_count + 1\n",
    "\n",
    "\n",
    "print(error_count, \" result(s) were excluded due to invalid data points.\")        \n",
    "\n",
    "# Change this list of dictionaries into a dataframe             \n",
    "df = pd.DataFrame(result) \n",
    "tweets = df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('DATA/temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place_name</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>947179596608364545</td>\n",
       "      <td>1351</td>\n",
       "      <td>@ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...</td>\n",
       "      <td>2017-12-30 18:56:28+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>{'place_id': 'e564d30dc173d2a8'}</td>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "      <td>[27.7518557, -26.5126489, 28.1843404, -26.0396...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>947173171156877319</td>\n",
       "      <td>813</td>\n",
       "      <td>@AndileDakuse @eNCA In 1993 was admitted in 3 ...</td>\n",
       "      <td>2017-12-30 18:30:56+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'place_id': 'f16913d3f6acb7f1'}</td>\n",
       "      <td>Mamelodi, South Africa</td>\n",
       "      <td>[28.3213448, -25.7363127, 28.4520433, -25.6853...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  author_followers  \\\n",
       "0  947179596608364545              1351   \n",
       "1  947173171156877319               813   \n",
       "\n",
       "                                                text  \\\n",
       "0  @ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...   \n",
       "1  @AndileDakuse @eNCA In 1993 was admitted in 3 ...   \n",
       "\n",
       "                  created_at  retweets  replies  likes  quote_count  \\\n",
       "0  2017-12-30 18:56:28+00:00         1        3     11            0   \n",
       "1  2017-12-30 18:30:56+00:00         0        0      1            0   \n",
       "\n",
       "                           place_id                  place_name  \\\n",
       "0  {'place_id': 'e564d30dc173d2a8'}  Johannesburg, South Africa   \n",
       "1  {'place_id': 'f16913d3f6acb7f1'}      Mamelodi, South Africa   \n",
       "\n",
       "                                                bbox  \n",
       "0  [27.7518557, -26.5126489, 28.1843404, -26.0396...  \n",
       "1  [28.3213448, -25.7363127, 28.4520433, -25.6853...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('DATA/temp.csv')\n",
    "tweets = tweets.drop(['Unnamed: 0'], axis=1)\n",
    "tweets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place_name</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>947179596608364545</td>\n",
       "      <td>1351</td>\n",
       "      <td>@ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...</td>\n",
       "      <td>2017-12-30 18:56:28+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>{'place_id': 'e564d30dc173d2a8'}</td>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "      <td>[27.7518557, -26.5126489, 28.1843404, -26.0396...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  author_followers  \\\n",
       "0  947179596608364545              1351   \n",
       "\n",
       "                                                text  \\\n",
       "0  @ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...   \n",
       "\n",
       "                  created_at  retweets  replies  likes  quote_count  \\\n",
       "0  2017-12-30 18:56:28+00:00         1        3     11            0   \n",
       "\n",
       "                           place_id                  place_name  \\\n",
       "0  {'place_id': 'e564d30dc173d2a8'}  Johannesburg, South Africa   \n",
       "\n",
       "                                                bbox  \n",
       "0  [27.7518557, -26.5126489, 28.1843404, -26.0396...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the previous stuff to it... tweets, location and geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size of dataset before dropping duplicated rows: (17983, 11)\n",
      "Current size of dataset after dropping duplicated rows, if any, is: (17983, 11)\n"
     ]
    }
   ],
   "source": [
    "print('Initial size of dataset before dropping duplicated rows:', tweets.shape)\n",
    "tweets.drop_duplicates(keep = False, inplace = True)\n",
    "\n",
    "print('Current size of dataset after dropping duplicated rows, if any, is:', tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17983"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.dropna(subset = ['text'], inplace = True)\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Havent added links and stuff here... We likley wont use in final product. Futhermore text has not been cleaned as this is not needed by either content or sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Boundry Box to a set of coordinates of Latitude and Longitude\n",
    "There are a few ways of doing this\n",
    "* Take an average and find the middle of the Boundry Box\n",
    "* Indentify where the location is using another API based on place_name\n",
    "* Keep the location as a polygon and then place each user into a munucipality in hich the area is largest\n",
    "\n",
    "The way we will do it here is using centroid of the boundry box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run from here ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_to_coords(bbox):\n",
    "    all_coords = bbox.split()\n",
    "    coords = []\n",
    "    for coordinate in all_coords:\n",
    "        coordinate = coordinate.replace('[','')\n",
    "        coordinate = coordinate.replace(']','')\n",
    "        coordinate = coordinate.replace(',','')\n",
    "        coord = float(coordinate)\n",
    "        coords.append(coord)\n",
    "\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['coords'] = tweets['bbox'].apply(lambda x: bbox_to_coords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['longitude_1'] = tweets['coords'].apply(lambda x: x[0])\n",
    "tweets['latitude_1'] = tweets['coords'].apply(lambda x: x[1])\n",
    "tweets['longitude_2'] = tweets['coords'].apply(lambda x: x[2])\n",
    "tweets['latitude_2'] = tweets['coords'].apply(lambda x: x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.drop('bbox', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(coords):\n",
    "    geometry = LineString([(coords[0], coords[1]),(coords[2], coords[3])])\n",
    "    centroid = geometry.centroid\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place_name</th>\n",
       "      <th>coords</th>\n",
       "      <th>longitude_1</th>\n",
       "      <th>latitude_1</th>\n",
       "      <th>longitude_2</th>\n",
       "      <th>latitude_2</th>\n",
       "      <th>centroid_long</th>\n",
       "      <th>centroid_lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>947179596608364545</td>\n",
       "      <td>1351</td>\n",
       "      <td>@ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...</td>\n",
       "      <td>2017-12-30 18:56:28+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>{'place_id': 'e564d30dc173d2a8'}</td>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "      <td>[27.7518557, -26.5126489, 28.1843404, -26.0396...</td>\n",
       "      <td>27.751856</td>\n",
       "      <td>-26.512649</td>\n",
       "      <td>28.184340</td>\n",
       "      <td>-26.039628</td>\n",
       "      <td>27.968098</td>\n",
       "      <td>-26.276139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>947173171156877319</td>\n",
       "      <td>813</td>\n",
       "      <td>@AndileDakuse @eNCA In 1993 was admitted in 3 ...</td>\n",
       "      <td>2017-12-30 18:30:56+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'place_id': 'f16913d3f6acb7f1'}</td>\n",
       "      <td>Mamelodi, South Africa</td>\n",
       "      <td>[28.3213448, -25.7363127, 28.4520433, -25.6853...</td>\n",
       "      <td>28.321345</td>\n",
       "      <td>-25.736313</td>\n",
       "      <td>28.452043</td>\n",
       "      <td>-25.685311</td>\n",
       "      <td>28.386694</td>\n",
       "      <td>-25.710812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>947172303732912129</td>\n",
       "      <td>9119</td>\n",
       "      <td>@UliMahlangu President  Zuma stole the thunder...</td>\n",
       "      <td>2017-12-30 18:27:29+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>{'place_id': '8b9ec16fdc0d7e55'}</td>\n",
       "      <td>Cape Town, South Africa</td>\n",
       "      <td>[18.3180332, -34.35839, 18.6600898, -33.8849254]</td>\n",
       "      <td>18.318033</td>\n",
       "      <td>-34.358390</td>\n",
       "      <td>18.660090</td>\n",
       "      <td>-33.884925</td>\n",
       "      <td>18.489061</td>\n",
       "      <td>-34.121658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  author_followers  \\\n",
       "0  947179596608364545              1351   \n",
       "1  947173171156877319               813   \n",
       "2  947172303732912129              9119   \n",
       "\n",
       "                                                text  \\\n",
       "0  @ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...   \n",
       "1  @AndileDakuse @eNCA In 1993 was admitted in 3 ...   \n",
       "2  @UliMahlangu President  Zuma stole the thunder...   \n",
       "\n",
       "                  created_at  retweets  replies  likes  quote_count  \\\n",
       "0  2017-12-30 18:56:28+00:00         1        3     11            0   \n",
       "1  2017-12-30 18:30:56+00:00         0        0      1            0   \n",
       "2  2017-12-30 18:27:29+00:00         2        2      3            0   \n",
       "\n",
       "                           place_id                  place_name  \\\n",
       "0  {'place_id': 'e564d30dc173d2a8'}  Johannesburg, South Africa   \n",
       "1  {'place_id': 'f16913d3f6acb7f1'}      Mamelodi, South Africa   \n",
       "2  {'place_id': '8b9ec16fdc0d7e55'}     Cape Town, South Africa   \n",
       "\n",
       "                                              coords  longitude_1  latitude_1  \\\n",
       "0  [27.7518557, -26.5126489, 28.1843404, -26.0396...    27.751856  -26.512649   \n",
       "1  [28.3213448, -25.7363127, 28.4520433, -25.6853...    28.321345  -25.736313   \n",
       "2   [18.3180332, -34.35839, 18.6600898, -33.8849254]    18.318033  -34.358390   \n",
       "\n",
       "   longitude_2  latitude_2  centroid_long  centroid_lat  \n",
       "0    28.184340  -26.039628      27.968098    -26.276139  \n",
       "1    28.452043  -25.685311      28.386694    -25.710812  \n",
       "2    18.660090  -33.884925      18.489061    -34.121658  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['centroid'] = tweets['coords'].apply(lambda x: find_centroid(x))\n",
    "tweets['centroid_long'] = tweets['centroid'].apply(lambda z: z.x)\n",
    "tweets['centroid_lat'] = tweets['centroid'].apply(lambda z: z.y)\n",
    "tweets = tweets.drop('centroid', axis =1)\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Edge Cases\n",
    "* Cape Town\n",
    "* Betty's Bay\n",
    "* Bloubergstrand\n",
    "* Mdumbi Beach \n",
    "</br>\n",
    "Using: https://www.distancesto.com/coordinates/za/bloubergstrand-latitude-longitude/history/76385.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[tweets.place_name == 'Cape Town, South Africa', ['centroid_long', 'centroid_lat']] = 18.4241, -33.9249\n",
    "tweets.loc[tweets.place_name == 'Mdumbi Beach', ['centroid_long', 'centroid_lat']] = 29.215369, -31.933896\n",
    "tweets.loc[tweets.place_name == \"Betty's Bay, South Africa\", ['centroid_long', 'centroid_lat']] = 18.92051, -34.34747\n",
    "tweets.loc[tweets.place_name == 'Bloubergstrand', ['centroid_long', 'centroid_lat']] = 18.46173, -33.800418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(tweets['centroid_long'], tweets['centroid_lat'])]\n",
    "gdf = GeoDataFrame(tweets, geometry=geometry) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place_name</th>\n",
       "      <th>coords</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>947179596608364545</td>\n",
       "      <td>1351</td>\n",
       "      <td>@ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...</td>\n",
       "      <td>2017-12-30 18:56:28+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>{'place_id': 'e564d30dc173d2a8'}</td>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "      <td>[27.7518557, -26.5126489, 28.1843404, -26.0396...</td>\n",
       "      <td>POINT (27.96810 -26.27614)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>947173171156877319</td>\n",
       "      <td>813</td>\n",
       "      <td>@AndileDakuse @eNCA In 1993 was admitted in 3 ...</td>\n",
       "      <td>2017-12-30 18:30:56+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'place_id': 'f16913d3f6acb7f1'}</td>\n",
       "      <td>Mamelodi, South Africa</td>\n",
       "      <td>[28.3213448, -25.7363127, 28.4520433, -25.6853...</td>\n",
       "      <td>POINT (28.38669 -25.71081)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  author_followers  \\\n",
       "0  947179596608364545              1351   \n",
       "1  947173171156877319               813   \n",
       "\n",
       "                                                text  \\\n",
       "0  @ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...   \n",
       "1  @AndileDakuse @eNCA In 1993 was admitted in 3 ...   \n",
       "\n",
       "                  created_at  retweets  replies  likes  quote_count  \\\n",
       "0  2017-12-30 18:56:28+00:00         1        3     11            0   \n",
       "1  2017-12-30 18:30:56+00:00         0        0      1            0   \n",
       "\n",
       "                           place_id                  place_name  \\\n",
       "0  {'place_id': 'e564d30dc173d2a8'}  Johannesburg, South Africa   \n",
       "1  {'place_id': 'f16913d3f6acb7f1'}      Mamelodi, South Africa   \n",
       "\n",
       "                                              coords  \\\n",
       "0  [27.7518557, -26.5126489, 28.1843404, -26.0396...   \n",
       "1  [28.3213448, -25.7363127, 28.4520433, -25.6853...   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (27.96810 -26.27614)  \n",
       "1  POINT (28.38669 -25.71081)  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop('longitude_1', axis=1)\n",
    "tweets = tweets.drop('longitude_2', axis=1)\n",
    "tweets = tweets.drop('latitude_1', axis=1)\n",
    "tweets = tweets.drop('latitude_2', axis=1)\n",
    "tweets = tweets.drop('centroid_long', axis=1)\n",
    "tweets = tweets.drop('centroid_lat', axis=1)\n",
    "tweets.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Useless locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>place_id</th>\n",
       "      <th>place_name</th>\n",
       "      <th>coords</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>947179596608364545</td>\n",
       "      <td>1351</td>\n",
       "      <td>@ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...</td>\n",
       "      <td>2017-12-30 18:56:28+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>{'place_id': 'e564d30dc173d2a8'}</td>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "      <td>[27.7518557, -26.5126489, 28.1843404, -26.0396...</td>\n",
       "      <td>POINT (27.96810 -26.27614)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>947173171156877319</td>\n",
       "      <td>813</td>\n",
       "      <td>@AndileDakuse @eNCA In 1993 was admitted in 3 ...</td>\n",
       "      <td>2017-12-30 18:30:56+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{'place_id': 'f16913d3f6acb7f1'}</td>\n",
       "      <td>Mamelodi, South Africa</td>\n",
       "      <td>[28.3213448, -25.7363127, 28.4520433, -25.6853...</td>\n",
       "      <td>POINT (28.38669 -25.71081)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  author_followers  \\\n",
       "0  947179596608364545              1351   \n",
       "1  947173171156877319               813   \n",
       "\n",
       "                                                text  \\\n",
       "0  @ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...   \n",
       "1  @AndileDakuse @eNCA In 1993 was admitted in 3 ...   \n",
       "\n",
       "                  created_at  retweets  replies  likes  quote_count  \\\n",
       "0  2017-12-30 18:56:28+00:00         1        3     11            0   \n",
       "1  2017-12-30 18:30:56+00:00         0        0      1            0   \n",
       "\n",
       "                           place_id                  place_name  \\\n",
       "0  {'place_id': 'e564d30dc173d2a8'}  Johannesburg, South Africa   \n",
       "1  {'place_id': 'f16913d3f6acb7f1'}      Mamelodi, South Africa   \n",
       "\n",
       "                                              coords  \\\n",
       "0  [27.7518557, -26.5126489, 28.1843404, -26.0396...   \n",
       "1  [28.3213448, -25.7363127, 28.4520433, -25.6853...   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (27.96810 -26.27614)  \n",
       "1  POINT (28.38669 -25.71081)  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets[tweets['place_name'] != 'South Africa']\n",
    "tweets.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding location based on shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nan\n",
    "from cmath import nan\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import folium\n",
    "from shapely.geometry import LineString\n",
    "from sympy import centroid\n",
    "from geopandas import GeoDataFrame\n",
    "# importing geopy library\n",
    "from geopy.geocoders import Nominatim\n",
    "from numpy import NaN\n",
    "from shapely import wkt\n",
    "\n",
    "# importing all the dependancies\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, Polygon\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting created at to a datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dates = tweets['created_at']\n",
    "datesOBJ =[]\n",
    "for date in dates:\n",
    "    date_object = datetime.fromisoformat(date)\n",
    "    date_object = date_object.date()\n",
    "    datesOBJ.append(date_object)\n",
    "\n",
    "tweets['Date'] = datesOBJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[['text','Date','geometry','author_followers','retweets','replies','likes','quote_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Date</th>\n",
       "      <th>geometry</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>POINT (27.96810 -26.27614)</td>\n",
       "      <td>1351</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@AndileDakuse @eNCA In 1993 was admitted in 3 ...</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>POINT (28.38669 -25.71081)</td>\n",
       "      <td>813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        Date  \\\n",
       "0  @ItIsSeRomeo @maggsnaidu @Julius_S_Malema My q...  2017-12-30   \n",
       "1  @AndileDakuse @eNCA In 1993 was admitted in 3 ...  2017-12-30   \n",
       "\n",
       "                     geometry  author_followers  retweets  replies  likes  \\\n",
       "0  POINT (27.96810 -26.27614)              1351         1        3     11   \n",
       "1  POINT (28.38669 -25.71081)               813         0        0      1   \n",
       "\n",
       "   quote_count  \n",
       "0            0  \n",
       "1            0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding the sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be way better if i made this a pandas function as opposed to creating a separte list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe with the text as the list\n",
    "text = tweets['text'].tolist()\n",
    "text = pd.DataFrame(text, columns = ['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a cleaning text function... very simular to the one in tweet_cleaning. May just combine this into one function in tweet cleaning. \n",
    "def cleanTxt(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # removes mentions\n",
    "    text = re.sub(r'#', '', text) # removes #\n",
    "    text = re.sub(r'RT[\\s]+', '', text) # removes RT\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) # removes hyper link\n",
    "\n",
    "    return text\n",
    "text['Text']=text['Text'].apply(cleanTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# get the polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# function to compute the negative, neutral and positive analysis\n",
    "def getAnalysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "    \n",
    "text['Subjectivity'] = text['Text'].apply(getSubjectivity)\n",
    "text['Polarity'] = text['Text'].apply(getPolarity)\n",
    "text['Analysis'] = text['Polarity'].apply(getAnalysis)\n",
    "\n",
    "\n",
    "text = text.drop(['Text'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the subjectivity to the tweets\n",
    "tweets = pd.concat([tweets, text.reindex(tweets.index)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define String Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_substring(string, substring):\n",
    "    # Lower ensures that the vocab is case insensitive\n",
    "    string = string.lower()\n",
    "    substring = substring.lower()\n",
    "\n",
    "    if substring in string:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Analysis method\n",
    "Takes in a vocabulary as argument and outputs a list that corresponds to a list of concepts for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_analysis(vocabulary):\n",
    "    list_ = []\n",
    "\n",
    "    # Loop Through Tweets\n",
    "    for iter_t, tweet in tweets.iterrows():\n",
    "        sub_list = []\n",
    "        #Loop Through Vocab\n",
    "        for iter_g, vocab in vocabulary.iterrows():\n",
    "            # Loop Through Phrases in Vocab\n",
    "            for phrase in vocab['Phrases']:\n",
    "                # Check if Phrase is in Text\n",
    "                if string_substring(tweet['text'], phrase):\n",
    "                    if vocab['Conditional_Phrases'] != vocab['Conditional_Phrases']:\n",
    "                        sub_list.append(vocab['Concept'])\n",
    "                        break\n",
    "                    else:\n",
    "                        # Loop Through Conditional Phrases in Vocab\n",
    "                        for con_phrase in vocab['Conditional_Phrases']:\n",
    "                            # Check to see if there are Conditional Phrases otherwise break\n",
    "                            if string_substring(tweet['text'], con_phrase):\n",
    "                                sub_list.append(vocab['Concept'])\n",
    "                                break\n",
    "                            # Check if the conditional phrase has a NOT Operator\n",
    "                            elif '%not%' in con_phrase:\n",
    "                                con_phrase = con_phrase[6:]\n",
    "                                if not string_substring(tweet['text'], con_phrase):\n",
    "                                    sub_list.append(vocab['Concept'])\n",
    "                                    break\n",
    "        if len(sub_list) != 0:\n",
    "            list_.append(sub_list)\n",
    "        else:\n",
    "            list_.append(nan)\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in All Vocabs\n",
    "And ensure all vocab lists set up correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(string):\n",
    "    if string == string:\n",
    "        string = string.lower()\n",
    "        string = string.replace(\"'\", \"\")\n",
    "        out = string.strip('][').split(', ')\n",
    "        return out\n",
    "    else:\n",
    "        return nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grievances = pd.read_excel('DATA/Vocabularies/grievances.xlsx')\n",
    "grievances.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "grievances['Phrases'] = grievances['Phrases'].apply(lambda x: split_string(x))\n",
    "grievances['Conditional_Phrases'] = grievances['Conditional_Phrases'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "triggers = pd.read_excel('DATA/Vocabularies/trigger.xlsx')\n",
    "triggers.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "triggers['Phrases'] = triggers['Phrases'].apply(lambda x: split_string(x))\n",
    "triggers['Conditional_Phrases'] = triggers['Conditional_Phrases'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tactics = pd.read_excel('DATA/Vocabularies/tactic.xlsx')\n",
    "tactics.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "tactics['Phrases'] = tactics['Phrases'].apply(lambda x: split_string(x))\n",
    "tactics['Conditional_Phrases'] = tactics['Conditional_Phrases'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = pd.read_excel('DATA/Vocabularies/actors.xlsx')\n",
    "actors.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "actors['Phrases'] = actors['Phrases'].apply(lambda x: split_string(x))\n",
    "actors['Conditional_Phrases'] = actors['Conditional_Phrases'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_excel('DATA/Vocabularies/locations.xlsx')\n",
    "locations.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "locations['Phrases'] = locations['Phrases'].apply(lambda x: split_string(x))\n",
    "locations['Conditional_Phrases'] = locations['Conditional_Phrases'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapons = pd.read_excel('DATA/Vocabularies/weapons.xlsx')\n",
    "weapons.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "weapons['Phrases'] = weapons['Phrases'].apply(lambda x: split_string(x))\n",
    "weapons['Conditional_Phrases'] = weapons['Conditional_Phrases'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventualities = pd.read_excel('DATA/Vocabularies/eventuality.xlsx')\n",
    "eventualities.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "eventualities['Phrases'] = eventualities['Phrases'].apply(lambda x: split_string(x))\n",
    "eventualities['Conditional_Phrases'] = eventualities['Conditional_Phrases'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "curiosities = pd.read_excel('DATA/Vocabularies/curiosity.xlsx')\n",
    "curiosities.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "curiosities['Phrases'] = curiosities['Phrases'].apply(lambda x: split_string(x))\n",
    "curiosities['Conditional_Phrases'] = curiosities['Conditional_Phrases'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_protests = pd.read_excel('DATA/Vocabularies/non_protest.xlsx')\n",
    "non_protests.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "non_protests['Phrases'] = non_protests['Phrases'].apply(lambda x: split_string(x))\n",
    "non_protests['Conditional_Phrases'] = non_protests['Conditional_Phrases'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Content Analysis for all vocabs:\n",
    "* Grievances\n",
    "* Trigger\n",
    "* Tactic\n",
    "* Actors\n",
    "* Location\n",
    "* Weapons\n",
    "* Eventuality\n",
    "* Curiosity\n",
    "* Non-Protest\n",
    "\n",
    "</br>\n",
    "And Remove any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_list(x):\n",
    "    if x == x:\n",
    "        return list(set(x))\n",
    "    else:\n",
    "        return nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['grievances'] = content_analysis(grievances)\n",
    "tweets['grievances'] = tweets['grievances'].apply(lambda x: unique_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['triggers'] = content_analysis(triggers)\n",
    "tweets['triggers'] = tweets['triggers'].apply(lambda x: unique_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tactics'] = content_analysis(tactics)\n",
    "tweets['tactics'] = tweets['tactics'].apply(lambda x: unique_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['actors'] = content_analysis(actors)\n",
    "tweets['actors'] = tweets['actors'].apply(lambda x: unique_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['locations'] = content_analysis(locations)\n",
    "tweets['locations'] = tweets['locations'].apply(lambda x: unique_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['weapons'] = content_analysis(weapons)\n",
    "tweets['weapons'] = tweets['weapons'].apply(lambda x: unique_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['eventualities'] = content_analysis(eventualities)\n",
    "tweets['eventualities'] = tweets['eventualities'].apply(lambda x: unique_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['curiosities'] = content_analysis(curiosities)\n",
    "tweets['curiosities'] = tweets['curiosities'].apply(lambda x: unique_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['non_protests'] = content_analysis(non_protests)\n",
    "tweets['non_protests'] = tweets['non_protests'].apply(lambda x: unique_list(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content and Frequency Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_table = pd.read_excel('DATA/Protest is SA   SAS rules V2 - Separated.xlsx')\n",
    "content_table = content_table.drop('Phrases', axis =1)\n",
    "content_table = content_table.drop('Conditional_Phrases', axis =1)\n",
    "content_table = content_table.drop('Afrikaans_Phrases', axis =1)\n",
    "content_table = content_table.drop('Rule', axis =1)\n",
    "content_table['Occurances'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurances(col_name, label):\n",
    "    global content_table\n",
    "    occurances = list(content_table['Occurances'])\n",
    "    for iter_t, tweet in tweets.iterrows():\n",
    "            if tweet[col_name] == tweet[col_name]:\n",
    "                for content in tweet[col_name]:\n",
    "                    for iter_c, concept in content_table.iterrows():\n",
    "                        if concept['Concept'] == content:\n",
    "                            if concept['Label'] == label:\n",
    "                                occurances[iter_c] += 1\n",
    "                            \n",
    "    content_table = content_table.drop('Occurances', axis =1)\n",
    "    content_table['Occurances'] = occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted Grievances!\n",
      "Counted Triggers!\n",
      "Counted Tactics!\n",
      "Counted Actors!\n",
      "Counted Locations!\n",
      "Counted Weapons!\n",
      "Counted Eventualities!\n",
      "Counted Curiosities!\n",
      "Counted Non-Protests!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count_occurances('grievances', 'Grievance')\n",
    "print('Counted Grievances!')\n",
    "count_occurances('triggers', 'Trigger')\n",
    "print('Counted Triggers!')\n",
    "count_occurances('tactics', 'Tactic')\n",
    "print('Counted Tactics!')\n",
    "count_occurances('actors', 'Actors')\n",
    "print('Counted Actors!')\n",
    "count_occurances('locations', 'Location')\n",
    "print('Counted Locations!')\n",
    "count_occurances('weapons', 'Weapons')\n",
    "print('Counted Weapons!')\n",
    "count_occurances('eventualities', 'Eventuality')\n",
    "print('Counted Eventualities!')\n",
    "count_occurances('curiosities', 'Curiosity')\n",
    "print('Counted Curiosities!')\n",
    "count_occurances('non_protests', 'Non-protest')\n",
    "print('Counted Non-Protests!')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_table.to_csv('DATA/Content Table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(tweets)\n",
    "frequency_table = content_table.groupby('Label').Occurances.sum().reset_index()\n",
    "frequency_table['Frequency'] = frequency_table['Occurances'].apply(lambda x: round((x/total)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_table.to_csv('DATA/Frequency Content Table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University Locator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities = pd.read_excel('DATA/South African Universities.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_substring_case_sensitive(string, substring):\n",
    "    # Lower ensures that the vocab is case insensitive\n",
    "    if substring in string:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities['Nickname'] = universities['Nickname'].apply(lambda x: split_string(x))\n",
    "universities['Abbriviation'] = universities['Abbriviation'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def university_locator():\n",
    "    addition = []\n",
    "    for iter_t, tweet in tweets.iterrows():\n",
    "        coords = []\n",
    "        words = []\n",
    "        for iter_u, uni in universities.iterrows():\n",
    "            if uni['Nickname'] == uni['Nickname']:\n",
    "                for nickname in uni['Nickname']:\n",
    "                    if string_substring(tweet['text'], nickname):\n",
    "                        # coords = [uni['Latitude'], uni['Longitude']]#lat, long\n",
    "                        words.append(uni['Universities'])\n",
    "            if uni['Abbriviation'] == uni['Abbriviation']:        \n",
    "                for abbr in uni['Abbriviation']:\n",
    "                    if string_substring_case_sensitive(tweet['text'], abbr):\n",
    "                        words.append(uni['Universities'])\n",
    "                \n",
    "                if string_substring(tweet['text'], uni['Universities']):\n",
    "                    words.append(uni['Universities'])\n",
    "        words = list(set(words))\n",
    "        if len(words) == 0:\n",
    "            words = nan\n",
    "        addition.append(words)\n",
    "\n",
    "    return addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['universities'] = university_locator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_coords():\n",
    "    for iter_t, tweet in tweets.iterrows():\n",
    "        if tweet['universities'] == tweet['universities']:\n",
    "            if len(tweet['universities']) == 1:\n",
    "                new_lat = (list(universities.loc[universities['Universities'] == tweet['universities'][0], 'Latitude']))[0]\n",
    "                new_long = (list(universities.loc[universities['Universities'] == tweet['universities'][0], 'Longitude']))[0]\n",
    "                new_geometry = Point(new_long,new_lat)\n",
    "                tweets['geometry'][iter_t] = new_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_coords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16843, 21)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets.to_csv('DATA/rawtweets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb1e2aa17c9c03522ea469ed025d74c8a00b3c7801d0496b408e209436a13f2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
