{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from statistics import multimode\n",
    "from cmath import nan\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(string):\n",
    "    if string == string:\n",
    "        string = string.replace(\"'\", \"\")\n",
    "        out = string.strip('][').split(', ')\n",
    "        return out\n",
    "    else:\n",
    "        return nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subregion(dist1, dist2, place):\n",
    "    row = dist1.loc[dist1['Place0']==place]\n",
    "    shape = row['geometry'].to_list()\n",
    "    shape = shape[0]\n",
    "\n",
    "    places = dist2['geometry']\n",
    "    res = places.within(shape)\n",
    "    res = res.to_list()\n",
    "    temp = dist2\n",
    "    temp['res'] = res\n",
    "    temp = temp.loc[temp['res']==True]\n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Tweets(dist, tweets, n):    \n",
    "    Nu_Tweets = []\n",
    "    for index, row in dist.iterrows():\n",
    "        size = len(tweets.loc[tweets['Place' + str(n)]==row['Place'+ str(n)]])\n",
    "\n",
    "        Nu_Tweets.append(size)\n",
    "\n",
    "    Nu_Tweets\n",
    "    dist['Tweets'] = Nu_Tweets\n",
    "\n",
    "    plot = dist.explore(\n",
    "        column=\"Tweets\", # make choropleth based on \"Data\" column\n",
    "        tooltip=['Place'+ str(n),'Tweets'], # show \"Province, Data\" value in tooltip (on hover)\n",
    "        popup=True, # show all values in popup (on click)\n",
    "        tiles=\"CartoDB positron\", # use \"CartoDB positron\" tiles\n",
    "        cmap=\"Paired\", # https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "        style_kwds=dict(color=\"black\") # use black outline\n",
    "        )\n",
    "    return(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_rate_av2(dates, tweets):\n",
    "    tweet_day = [0]*10\n",
    "    for i, date in enumerate(dates):\n",
    "        day = date\n",
    "        d1 = day - timedelta(days=5) \n",
    "        d2 = day + timedelta(days=5) \n",
    "        delta = (d2-d1).days\n",
    "        for i in range(delta):\n",
    "            day = d1+timedelta(days=i)\n",
    "            NuTweets = len(tweets.loc[tweets['Date']==day]) \n",
    "            tweet_day[i]=tweet_day[i]+NuTweets\n",
    "\n",
    "    # getting the average\n",
    "    tweet_day =[x/len(dates) for x in tweet_day]\n",
    "\n",
    "    # normalising\n",
    "    #tweet_day =[x/max(tweet_day) for x in tweet_day]\n",
    "\n",
    "    # Getting the average of the sets\n",
    "    average1 = [sum(tweet_day)/len(tweet_day)]*10\n",
    "\n",
    "    # this is just for the x axis\n",
    "    date = list(range(1,10+1))\n",
    "\n",
    "\n",
    "    plt.plot(date,tweet_day, \"-r\", label=\"Tweets\")\n",
    "    plt.plot(date,average1,\"-b\", label=\"Average Over All Set Dates\")\n",
    "    plt.axvline(x = 5, color = 'y', label = 'Centre (location of protest/non-protests)')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylabel('Number of Tweets')\n",
    "    plt.xlabel('Date')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_rate2(dates, tweets):\n",
    "    for date in dates:\n",
    "        day = date\n",
    "        d1 = day - timedelta(days=5) \n",
    "        d2 = day + timedelta(days=5) \n",
    "        date2 = []\n",
    "        tweet_day = []\n",
    "        delta = (d2-d1).days\n",
    "\n",
    "        for i in range(delta):\n",
    "            day = d1+timedelta(days=i)\n",
    "            NuTweets = len(tweets.loc[tweets['Date']==day]) \n",
    "            date2.append(i)\n",
    "            tweet_day.append(NuTweets)\n",
    "\n",
    "        # Normalising\n",
    "        \n",
    "        if len(tweet_day) == 0:\n",
    "            tweet_day = [0]*(int(5*2))\n",
    "        else:\n",
    "            if max(tweet_day) == 0:\n",
    "                tweet_day = [0]*(int(5*2))\n",
    "            else:\n",
    "                tweet_day =[x/max(tweet_day) for x in tweet_day]\n",
    "\n",
    "\n",
    "        plt.plot(date2,tweet_day)\n",
    "        plt.ylabel('Number of Tweets')\n",
    "        plt.xlabel('Date') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(protests,tweets):\n",
    "    start = tweets.tail(1)['Date'].to_list()\n",
    "    start = start[0]\n",
    "    end = tweets.head(1)['Date'].to_list()\n",
    "    end = end[0]\n",
    "\n",
    "    delta = (end-start).days\n",
    "    delta = delta\n",
    "    yes = []\n",
    "    no = []\n",
    "    protests2 = []\n",
    "\n",
    "    for i in range(delta):\n",
    "        date = start + timedelta(days=i)\n",
    "        temp = protests.loc[protests['Date']==date]\n",
    "        if temp.empty:\n",
    "            no.append(date)\n",
    "        else:\n",
    "            yes.append(date)\n",
    "    return(yes, no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start(protests, tweets, x):\n",
    "    dates = get_dates(protests, tweets)\n",
    "    yes = dates[0]\n",
    "    no = dates[1]\n",
    "\n",
    "\n",
    "    res = [1]*len(yes)\n",
    "    data = {'Protest':res,'Date':yes}\n",
    "    yes = pd.DataFrame(data)\n",
    "\n",
    "    res = [0]*len(no)\n",
    "    data = {'Protest':res,'Date':no}\n",
    "    no = pd.DataFrame(data)\n",
    "\n",
    "    # randomly sampling len(yes) samples from no such that there is an equal number of \n",
    "    # protests to non protest\n",
    "    #x = 46 # 0.83 & 0.75\n",
    "    # x = 54 # 0.87 0.53\n",
    "\n",
    "\n",
    "    no = no.sample(len(yes), random_state = x)\n",
    "\n",
    "    # Joining the dataframes, resetting the index and randomising the rows. \n",
    "    data = pd.concat([yes,no])\n",
    "    data = data.sample(frac=1, random_state = x)\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return(tweet_day,average,specifiedTweets,length)\n",
    "# return(likes,followers,retweets,replies,Subjectivity,Polarity)\n",
    "# return(centre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(date, tweets):\n",
    "    day = date\n",
    "    d1 = day - timedelta(days=5) \n",
    "    d2 = day + timedelta(days=5) \n",
    "    delta = (d2-d1).days\n",
    "    delta = int(delta)\n",
    "    tweet_day = [0]*(int(5*2))\n",
    "    tweet_day_zero = tweet_day\n",
    "    for i in range(10):\n",
    "        day = d1+timedelta(days=i)\n",
    "        NuTweets = len(tweets.loc[tweets['Date']==day]) \n",
    "        tweet_day[i]=tweet_day[i]+NuTweets\n",
    "    # average \n",
    "    average = sum(tweet_day)/len(tweet_day)\n",
    "    # normalising\n",
    "    if len(tweet_day) == 0:\n",
    "        tweet_day = tweet_day_zero\n",
    "    else:\n",
    "        if max(tweet_day) == 0:\n",
    "            tweet_day = [0]*(int(5*2))\n",
    "        else:\n",
    "            tweet_day =[x/max(tweet_day) for x in tweet_day]\n",
    "    # # average \n",
    "    # average = sum(tweet_day)/len(tweet_day)\n",
    "    # specific tweets.\n",
    "    specifiedTweets = tweets[((tweets['Date'] >d1)&(tweets['Date'] <d2))]\n",
    "    specifiedTweets = specifiedTweets.reset_index(drop=True)\n",
    "    length = len(specifiedTweets)\n",
    "\n",
    "    return(tweet_day,average,specifiedTweets,length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_lists_to_list(column_name, df):\n",
    "    content_list  = []\n",
    "    for iter_t, tweet in df.iterrows():\n",
    "        if tweet[column_name] == tweet[column_name]:\n",
    "            for content in tweet[column_name]:\n",
    "                content_list.append(content)\n",
    "    return content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_metrics(tweets):\n",
    "    length = len(tweets)\n",
    "    if length == 0:\n",
    "        length = 1\n",
    "    followers = (tweets['author_followers'].sum())/length\n",
    "    retweets = (tweets['retweets'].sum())/length\n",
    "    replies = (tweets['replies'].sum())/length\n",
    "    likes = (tweets['likes'].sum())/length\n",
    "    Subjectivity = (tweets['Subjectivity'].sum())/length\n",
    "    Polarity = (tweets['Polarity'].sum())/length\n",
    "    \n",
    "\n",
    "    grievance_list = concat_lists_to_list('grievances', tweets)\n",
    "    greivance_mode = multimode(grievance_list)\n",
    "\n",
    "    triggers_list = concat_lists_to_list('triggers', tweets)\n",
    "    triggers_mode = multimode(triggers_list)\n",
    "\n",
    "    tactics_list = concat_lists_to_list('tactics', tweets)\n",
    "    tactics_mode = multimode(tactics_list)\n",
    "\n",
    "    actors_list = concat_lists_to_list('actors', tweets)\n",
    "    actors_mode = multimode(actors_list)\n",
    "\n",
    "    locations_list = concat_lists_to_list('locations', tweets)\n",
    "    locations_mode = multimode(locations_list)\n",
    "\n",
    "    weapons_list = concat_lists_to_list('weapons', tweets)\n",
    "    weapons_mode = multimode(weapons_list)\n",
    "\n",
    "    eventualities_list = concat_lists_to_list('eventualities', tweets)\n",
    "    eventualities_mode = multimode(eventualities_list)\n",
    "\n",
    "    curiosities_list = concat_lists_to_list('curiosities', tweets)\n",
    "    curiosities_mode = multimode(curiosities_list)\n",
    "\n",
    "    non_protests_list = concat_lists_to_list('non_protests', tweets)\n",
    "    non_protests_mode = multimode(non_protests_list)\n",
    "\n",
    "    universities_list = concat_lists_to_list('universities', tweets)\n",
    "    universities_mode = multimode(universities_list)\n",
    "\n",
    "\n",
    "    return(likes,followers,retweets,replies,Subjectivity,Polarity,greivance_mode,triggers_mode,\n",
    "            tactics_mode,actors_mode,locations_mode,weapons_mode,eventualities_mode,\n",
    "            curiosities_mode,non_protests_mode,universities_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centre(tweets):\n",
    "    # locations = tweets['geometry'].centroid\n",
    "    # print(locations.head())\n",
    "    # locations = locations.reset_index(drop=True)\n",
    "    # centre = locations.centriod\n",
    "\n",
    "    # its not working for now\n",
    "    # centre = 'too bad'\n",
    "    # return(centre)\n",
    "    \n",
    "\n",
    "    # We are going to return the place\n",
    "    if len(tweets['Place1'].value_counts()) == 0:\n",
    "        place = nan\n",
    "    else:\n",
    "        place = tweets['Place1'].value_counts().idxmax()\n",
    "    return(place)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training(data, tweets):\n",
    "    NuTweets = []\n",
    "    average = []\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    d3 = []\n",
    "    d4 = []\n",
    "    d5 = []\n",
    "    d6 = []\n",
    "    d7 = []\n",
    "    d8 = []\n",
    "    d9 = []\n",
    "    d10 = []\n",
    "\n",
    "    likes = []\n",
    "    followers = []\n",
    "    retweets = []\n",
    "    replies = []\n",
    "    sub = []\n",
    "    pol = []\n",
    "    griev = []\n",
    "    trigg = []\n",
    "    tact = []\n",
    "    act = []\n",
    "    loca = []\n",
    "    weap = []\n",
    "    even = []\n",
    "    curi = []\n",
    "    nonp = []\n",
    "    uni = []\n",
    "\n",
    "    centre = []\n",
    "\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        date = row['Date']\n",
    "        \n",
    "        res1 = get_tweets(date,tweets)\n",
    "        res2 = tweet_metrics(res1[2])\n",
    "        res3 = get_centre(res1[2])\n",
    "\n",
    "\n",
    "        average.append(res1[1])\n",
    "        NuTweets.append(res1[3])\n",
    "        d1.append(res1[0][0])\n",
    "        d2.append(res1[0][1])\n",
    "        d3.append(res1[0][2])\n",
    "        d4.append(res1[0][3])\n",
    "        d5.append(res1[0][4])\n",
    "        d6.append(res1[0][5])\n",
    "        d7.append(res1[0][6])\n",
    "        d8.append(res1[0][7])\n",
    "        d9.append(res1[0][8])\n",
    "        d10.append(res1[0][9])\n",
    "\n",
    "\n",
    "        likes.append(res2[0])\n",
    "        followers.append(res2[1])\n",
    "        retweets.append(res2[2])\n",
    "        replies.append(res2[3])\n",
    "        sub.append(res2[4])\n",
    "        pol.append(res2[5])\n",
    "        griev.append(res2[6])\n",
    "        trigg.append(res2[7])\n",
    "        tact.append(res2[8])\n",
    "        act.append(res2[9])\n",
    "        loca.append(res2[10])\n",
    "        weap.append(res2[11])\n",
    "        even.append(res2[12])\n",
    "        curi.append(res2[13])\n",
    "        nonp.append(res2[14])\n",
    "        uni.append(res2[15])\n",
    "        \n",
    "\n",
    "        centre.append(res3)\n",
    "\n",
    "    \n",
    "\n",
    "    metrics = {'NuTweets':NuTweets,'d1':d1,'d2':d2,'d3':d3,'d4':d4,\n",
    "               'd5':d5,'d6':d6,'d7':d7,'d8':d8,'d9':d9,'d10':d10,\n",
    "               'average':average,'likes':likes,'followers':followers,\n",
    "               'retweets':retweets,'replies':replies,'sub':sub,'pol':pol,\n",
    "               'place':centre,'grievances':griev, 'triggers': trigg,\n",
    "               'tactics': tact, 'actors': act, 'locations': loca,\n",
    "               'weapons': weap, 'eventualities': even, 'curiosities': curi,\n",
    "               'non_protests':nonp, 'universities':uni}\n",
    "    metrics = pd.DataFrame(metrics)\n",
    "\n",
    "        \n",
    "    training = pd.concat([data,metrics.reindex(data.index)], axis=1)\n",
    "    training = training.drop(['Date'], axis = 1)\n",
    "    return(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(training):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(training.drop(['Protest','place', 'grievances', 'triggers', 'tactics', 'actors', 'locations', 'weapons', 'eventualities', 'curiosities', 'non_protests', 'universities'],axis = 1), training['Protest'],test_size = 0.3,random_state=1)\n",
    "    # training the model\n",
    "    logreg =  LogisticRegression(solver='lbfgs')\n",
    "    logreg.fit(X_train,y_train)\n",
    "    score = logreg.score(X_test,y_test)\n",
    "    return(logreg,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def niave(training):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(training.drop(['Protest','place', 'grievances', 'triggers', 'tactics', 'actors', 'locations', 'weapons', 'eventualities', 'curiosities', 'non_protests', 'universities'],axis = 1), training['Protest'],test_size = 0.2)\n",
    "    naive = GaussianNB()\n",
    "    naive.fit(X_train,y_train)\n",
    "    score = naive.score(X_test,y_test)\n",
    "    return(naive,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearSVM(training):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    X_train,X_test,y_train,y_test = train_test_split(training.drop(['Protest','place', 'grievances', 'triggers', 'tactics', 'actors', 'locations', 'weapons', 'eventualities', 'curiosities', 'non_protests', 'universities'],axis = 1), training['Protest'],test_size = 0.2)\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(X_train,y_train)\n",
    "    score = svm.score(X_test,y_test)\n",
    "    return(svm,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading tweets and protests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('DATA/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['grievances'] = tweets['grievances'].apply(lambda x: split_string(x))\n",
    "tweets['triggers'] = tweets['triggers'].apply(lambda x: split_string(x)) \n",
    "tweets['tactics'] = tweets['tactics'].apply(lambda x: split_string(x)) \n",
    "tweets['actors'] = tweets['actors'].apply(lambda x: split_string(x)) \n",
    "tweets['locations'] = tweets['locations'].apply(lambda x: split_string(x)) \n",
    "tweets['weapons'] = tweets['weapons'].apply(lambda x: split_string(x)) \n",
    "tweets['eventualities'] = tweets['eventualities'].apply(lambda x: split_string(x)) \n",
    "tweets['curiosities'] = tweets['curiosities'].apply(lambda x: split_string(x)) \n",
    "tweets['non_protests'] = tweets['non_protests'].apply(lambda x: split_string(x)) \n",
    "tweets['universities'] = tweets['universities'].apply(lambda x: split_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets['geometry'] = gpd.GeoSeries.from_wkt(tweets['geometry'])\n",
    "tweets['Date']=pd.to_datetime(tweets['Date'], format='%Y %m %d')\n",
    "tweets = tweets.drop(['Unnamed: 0','Analysis'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029\n"
     ]
    }
   ],
   "source": [
    "protests = pd.read_csv('DATA/protests.csv')\n",
    "protests['geometry'] = gpd.GeoSeries.from_wkt(protests['geometry'])\n",
    "protests['Date']=pd.to_datetime(protests['Date'], format='%Y %m %d')\n",
    "protests = protests.drop(['Unnamed: 0'],axis=1)\n",
    "protests.drop_duplicates(['Date','Place0'],keep= 'first',inplace =True)\n",
    "print(len(protests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Date</th>\n",
       "      <th>geometry</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>grievances</th>\n",
       "      <th>triggers</th>\n",
       "      <th>tactics</th>\n",
       "      <th>actors</th>\n",
       "      <th>locations</th>\n",
       "      <th>weapons</th>\n",
       "      <th>eventualities</th>\n",
       "      <th>curiosities</th>\n",
       "      <th>non_protests</th>\n",
       "      <th>universities</th>\n",
       "      <th>Place0</th>\n",
       "      <th>Place1</th>\n",
       "      <th>Place2</th>\n",
       "      <th>Place3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Cristiano your attitude stinks, if a player m...</td>\n",
       "      <td>2022-10-09</td>\n",
       "      <td>POINT (28.23140 -25.75450)</td>\n",
       "      <td>11305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Attack]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[University of Pretoria]</td>\n",
       "      <td>Gauteng</td>\n",
       "      <td>City of Tshwane</td>\n",
       "      <td>City of Tshwane</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       Date  \\\n",
       "0  @Cristiano your attitude stinks, if a player m... 2022-10-09   \n",
       "\n",
       "                     geometry  author_followers  retweets  replies  likes  \\\n",
       "0  POINT (28.23140 -25.75450)             11305         0        0      0   \n",
       "\n",
       "   quote_count  Subjectivity  Polarity grievances triggers   tactics actors  \\\n",
       "0            0           0.5      -0.6        NaN      NaN  [Attack]    NaN   \n",
       "\n",
       "  locations weapons eventualities curiosities non_protests  \\\n",
       "0       NaN     NaN           NaN         NaN          NaN   \n",
       "\n",
       "               universities   Place0           Place1           Place2  Place3  \n",
       "0  [University of Pretoria]  Gauteng  City of Tshwane  City of Tshwane      56  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>notes</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Place0</th>\n",
       "      <th>Place1</th>\n",
       "      <th>Place2</th>\n",
       "      <th>Place3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>On 28 September 2022, hundreds of students blo...</td>\n",
       "      <td>POINT (28.81580 -28.52420)</td>\n",
       "      <td>Free State</td>\n",
       "      <td>Thabo Mofutsanyane</td>\n",
       "      <td>Maluti a Phofung</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                              notes  \\\n",
       "0 2022-09-28  On 28 September 2022, hundreds of students blo...   \n",
       "\n",
       "                     geometry      Place0              Place1  \\\n",
       "0  POINT (28.81580 -28.52420)  Free State  Thabo Mofutsanyane   \n",
       "\n",
       "             Place2  Place3  \n",
       "0  Maluti a Phofung      27  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protests.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets test protest in a chosen place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Free State' 'KwaZulu-Natal' 'Gauteng' 'Limpopo' 'Eastern Cape'\n",
      " 'Western Cape' 'Mpumalanga' 'Nothern Cape' '0' 'North West']\n"
     ]
    }
   ],
   "source": [
    "places = protests['Place0'].unique()\n",
    "print(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gauteng' 'Western Cape' 'Eastern Cape' 'KwaZulu-Natal' 'Free State'\n",
      " 'Nothern Cape' 'Limpopo' 'Mpumalanga' 'North West' '0']\n"
     ]
    }
   ],
   "source": [
    "print(tweets['Place0'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sa_training = pd.DataFrame()\n",
    "for place in places:\n",
    "    p = protests.loc[(protests['Place0'] == place)]\n",
    "    t = tweets.loc[(tweets['Place0'] == place)]\n",
    "    if p.empty == False:\n",
    "        data = get_start(p, t, 5)\n",
    "        training = get_training(data, t)\n",
    "        sa_training = pd.concat([sa_training, training])\n",
    "sa_training.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# outcome = []\n",
    "\n",
    "# for x in range(1,20):\n",
    "#     sa_training = pd.DataFrame()\n",
    "#     for place in places:\n",
    "#         p = protests.loc[(protests['Place0'] == place)]\n",
    "#         t = tweets.loc[(tweets['Place0'] == place)]\n",
    "#         if p.empty == False:\n",
    "#             data = get_start(p, t, x)\n",
    "#             training = get_training(data, t)\n",
    "#             sa_training = pd.concat([sa_training, training])\n",
    "#     sa_training.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    \n",
    "\n",
    "#     log = logistic_regression(sa_training)\n",
    "#     lr = log[1]\n",
    "\n",
    "#     log = niave(training)\n",
    "#     na = log[1]\n",
    "\n",
    "#     log = linearSVM(sa_training)\n",
    "#     svm = log[1]\n",
    "\n",
    "#     models = [x, lr, na, svm]\n",
    "#     outcome.append(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.DataFrame(outcome)\n",
    "# results.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected Time for 20k tweets = seconds\n",
    "# data = get_start(protests,tweets)\n",
    "# training = get_training(data,tweets)\n",
    "# training.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_training.to_csv('DATA/training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2054, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_training.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5688816855753647"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = logistic_regression(sa_training)\n",
    "log[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190476190476191"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = niave(training)\n",
    "log[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\papag\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5109489051094891"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = linearSVM(sa_training)\n",
    "log[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protest</th>\n",
       "      <th>NuTweets</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>d10</th>\n",
       "      <th>average</th>\n",
       "      <th>likes</th>\n",
       "      <th>followers</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>sub</th>\n",
       "      <th>pol</th>\n",
       "      <th>place</th>\n",
       "      <th>grievances</th>\n",
       "      <th>triggers</th>\n",
       "      <th>tactics</th>\n",
       "      <th>actors</th>\n",
       "      <th>locations</th>\n",
       "      <th>weapons</th>\n",
       "      <th>eventualities</th>\n",
       "      <th>curiosities</th>\n",
       "      <th>non_protests</th>\n",
       "      <th>universities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.652174</td>\n",
       "      <td>11435.130435</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.400750</td>\n",
       "      <td>0.081879</td>\n",
       "      <td>Mangaung</td>\n",
       "      <td>[Electricity, Labour related]</td>\n",
       "      <td>[Utility connections]</td>\n",
       "      <td>[Gathering]</td>\n",
       "      <td>[Political Party]</td>\n",
       "      <td>[School, Tertiary Edu, Informal area]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Special Keywords]</td>\n",
       "      <td>[Election campaigns]</td>\n",
       "      <td>[University of Pretoria]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14079.000000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463988</td>\n",
       "      <td>0.117668</td>\n",
       "      <td>Mangaung</td>\n",
       "      <td>[Services A, International Solidarity, Healthc...</td>\n",
       "      <td>[Court hearing]</td>\n",
       "      <td>[Disrupt]</td>\n",
       "      <td>[Political Party]</td>\n",
       "      <td>[Court]</td>\n",
       "      <td>[Police weapons]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Election campaigns]</td>\n",
       "      <td>[Central University of Technology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>7509.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396750</td>\n",
       "      <td>-0.016710</td>\n",
       "      <td>Mangaung</td>\n",
       "      <td>[Electricity]</td>\n",
       "      <td>[Utility connections, Crime Event]</td>\n",
       "      <td>[March, Vandalism, Gathering]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Business premises]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[16 Days of activism]</td>\n",
       "      <td>[Central University of Technology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>68798.166667</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.258097</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>Mangaung</td>\n",
       "      <td>[Education, Police, Values]</td>\n",
       "      <td>[Arrests, Court hearing]</td>\n",
       "      <td>[Disrupt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[School, Tertiary Edu]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Special Keywords]</td>\n",
       "      <td>[Exhibitions, Election campaigns, 16 Days of a...</td>\n",
       "      <td>[Central University of Technology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>7470.600000</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.304179</td>\n",
       "      <td>0.052394</td>\n",
       "      <td>Mangaung</td>\n",
       "      <td>[Labour related, Education, Conditions]</td>\n",
       "      <td>[Court hearing]</td>\n",
       "      <td>[Gathering]</td>\n",
       "      <td>[Civic org, Political Party]</td>\n",
       "      <td>[Tertiary Edu]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Police attack]</td>\n",
       "      <td>[Special Keywords]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Central University of Technology]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protest  NuTweets        d1        d2        d3        d4        d5  \\\n",
       "0        1        23  0.000000  0.777778  0.000000  0.000000  0.111111   \n",
       "1        0        14  0.000000  0.333333  1.000000  0.333333  0.333333   \n",
       "2        1        10  0.666667  0.000000  0.666667  0.000000  0.000000   \n",
       "3        0        12  0.250000  0.250000  0.000000  0.500000  0.250000   \n",
       "4        1        40  0.666667  0.166667  0.916667  1.000000  0.333333   \n",
       "\n",
       "         d6        d7        d8        d9       d10  average     likes  \\\n",
       "0  0.111111  0.111111  1.000000  0.111111  0.333333      2.3  3.652174   \n",
       "1  0.333333  1.000000  1.000000  0.333333  0.000000      1.4  1.000000   \n",
       "2  1.000000  1.000000  0.000000  0.333333  0.333333      1.2  2.500000   \n",
       "3  1.000000  0.250000  0.250000  0.250000  0.250000      1.3  2.500000   \n",
       "4  0.583333  0.083333  0.083333  0.083333  0.083333      4.8  3.625000   \n",
       "\n",
       "      followers  retweets   replies       sub       pol     place  \\\n",
       "0  11435.130435  0.478261  0.782609  0.400750  0.081879  Mangaung   \n",
       "1  14079.000000  0.785714  0.500000  0.463988  0.117668  Mangaung   \n",
       "2   7509.000000  0.500000  1.000000  0.396750 -0.016710  Mangaung   \n",
       "3  68798.166667  2.083333  0.250000  0.258097 -0.019764  Mangaung   \n",
       "4   7470.600000  5.950000  0.375000  0.304179  0.052394  Mangaung   \n",
       "\n",
       "                                          grievances  \\\n",
       "0                      [Electricity, Labour related]   \n",
       "1  [Services A, International Solidarity, Healthc...   \n",
       "2                                      [Electricity]   \n",
       "3                        [Education, Police, Values]   \n",
       "4            [Labour related, Education, Conditions]   \n",
       "\n",
       "                             triggers                        tactics  \\\n",
       "0               [Utility connections]                    [Gathering]   \n",
       "1                     [Court hearing]                      [Disrupt]   \n",
       "2  [Utility connections, Crime Event]  [March, Vandalism, Gathering]   \n",
       "3            [Arrests, Court hearing]                      [Disrupt]   \n",
       "4                     [Court hearing]                    [Gathering]   \n",
       "\n",
       "                         actors                              locations  \\\n",
       "0             [Political Party]  [School, Tertiary Edu, Informal area]   \n",
       "1             [Political Party]                                [Court]   \n",
       "2                            []                    [Business premises]   \n",
       "3                            []                 [School, Tertiary Edu]   \n",
       "4  [Civic org, Political Party]                         [Tertiary Edu]   \n",
       "\n",
       "            weapons    eventualities         curiosities  \\\n",
       "0                []               []  [Special Keywords]   \n",
       "1  [Police weapons]               []                  []   \n",
       "2                []               []                  []   \n",
       "3                []               []  [Special Keywords]   \n",
       "4                []  [Police attack]  [Special Keywords]   \n",
       "\n",
       "                                        non_protests  \\\n",
       "0                               [Election campaigns]   \n",
       "1                               [Election campaigns]   \n",
       "2                              [16 Days of activism]   \n",
       "3  [Exhibitions, Election campaigns, 16 Days of a...   \n",
       "4                                                 []   \n",
       "\n",
       "                         universities  \n",
       "0            [University of Pretoria]  \n",
       "1  [Central University of Technology]  \n",
       "2  [Central University of Technology]  \n",
       "3  [Central University of Technology]  \n",
       "4  [Central University of Technology]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_training.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb1e2aa17c9c03522ea469ed025d74c8a00b3c7801d0496b408e209436a13f2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
